{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":470,"status":"ok","timestamp":1622274557516,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"_KlHP0O4dB_8"},"outputs":[],"source":["%matplotlib inline "]},{"cell_type":"markdown","metadata":{"id":"m1o0Zy-5dT-S"},"source":["pre-requisite python module"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1905,"status":"ok","timestamp":1622274562010,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"D3cQAhEydMze"},"outputs":[],"source":["import numpy as np                   # advanced math library\n","import matplotlib.pyplot as plt      # MATLAB like plotting routines \n","import random                        # for generating random numbers\n","\n","from keras.datasets import mnist     # MNIST dataset is included in Keras\n","from keras.models import Sequential  # Model type to be used\n","\n","from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n","from keras.utils import np_utils     "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":786,"status":"ok","timestamp":1622274566065,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"jC_dRWUPGKgc","outputId":"3ae85dfb-2f8e-42da-e4d2-ff3edbce4217"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","X_train shape (60000, 28, 28)\n","y_train shape (60000,)\n","X_test shape (10000, 28, 28)\n","y_test shape (10000,)\n"]}],"source":["# The MNIST data is split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel images\n","(X_train, y_train), (X_test, y_test) = mnist.load_data() \n","\n","print(\"X_train shape\", X_train.shape)\n","print(\"y_train shape\", y_train.shape)\n","print(\"X_test shape\", X_test.shape)\n","print(\"y_test shape\", y_test.shape)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"elapsed":341,"status":"ok","timestamp":1622274575146,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"ENiblWjWdh3d","outputId":"a5197968-5a86-45e8-fa35-bee5a28a8029"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 288x288 with 1 Axes\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["plt.rcParams['figure.figsize'] = (4,4) # Make the figures a bit bigger \n","\n","#for i in range(9):\n","plt.subplot(1,1,1)\n","#num = random.randint(0, len(X_train))\n","num = 31933 #image of number 2\n","plt.imshow(X_train[num], cmap='gray', interpolation='none')\n","plt.title(\"Class {}\".format(y_train[num]))\n","    \n","plt.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"hyi5wqrgeHCc"},"source":["Import additional python modules"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":310,"status":"ok","timestamp":1622274582776,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"kyFkf-fueJX7"},"outputs":[],"source":["# import some additional tools\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n","from keras.layers.normalization import BatchNormalization"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1622274587786,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"RiWqOT3XdPIi","outputId":"4947c81f-2026-4166-db2c-1032c420cb6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training matrix shape (60000, 28, 28, 1)\n","Testing matrix shape (10000, 28, 28, 1)\n"]}],"source":["# formatting\n","# Except we do not flatten each image into a 784-length vector because we want to perform convolutions first\n","\n","X_train = X_train.reshape(60000, 28, 28, 1) #add an additional dimension to represent the single-channel\n","X_test = X_test.reshape(10000, 28, 28, 1)\n","\n","X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n","X_test = X_test.astype('float32')\n","\n","X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n","X_test /= 255\n","\n","print(\"Training matrix shape\", X_train.shape)\n","print(\"Testing matrix shape\", X_test.shape)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":289,"status":"ok","timestamp":1622274596155,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"Nm2KKXf8elbJ"},"outputs":[],"source":["# one-hot format classes\n","\n","nb_classes = 10 # number of unique digits\n","\n","Y_train = np_utils.to_categorical(y_train, nb_classes)\n","Y_test = np_utils.to_categorical(y_test, nb_classes)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5558,"status":"ok","timestamp":1622274604662,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"vRPAhq7nesgN"},"outputs":[],"source":["model = Sequential()                                 # Linear stacking of layers\n","\n","# Convolution Layer 1\n","model.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n","model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n","convLayer01 = Activation('relu')                     # activation\n","model.add(convLayer01)\n","\n","# Convolution Layer 2\n","model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n","model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n","model.add(Activation('relu'))                        # activation\n","convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n","model.add(convLayer02)\n","\n","# Convolution Layer 3\n","model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n","model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n","convLayer03 = Activation('relu')                     # activation\n","model.add(convLayer03)\n","\n","# Convolution Layer 4\n","model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n","model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n","model.add(Activation('relu'))                        # activation\n","convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n","model.add(convLayer04)\n","\n","# Convolution Layer 5\n","model.add(Conv2D(128,(3, 3)))                         # 128 different 3x3 kernels -- so 64 feature maps\n","model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n","convLayer05 = Activation('relu')                     # activation\n","model.add(convLayer05)\n","\n","# Convolution Layer 6\n","#model.add(Conv2D(128, (3, 3)))                        # 128 different 3x3 kernels -- so 64 feature maps\n","#model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n","#model.add(Activation('relu'))                        # activation\n","#convLayer06 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n","#model.add(convLayer06)\n","\n","\n","model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n","\n","# Fully Connected Layer 5\n","model.add(Dense(512))                                # 512 FCN nodes\n","model.add(BatchNormalization())                      # normalization\n","model.add(Activation('relu'))                        # activation\n","\n","# Fully Connected Layer 6                       \n","model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n","model.add(Dense(10))                                 # final 10 FCN nodes\n","model.add(Activation('softmax'))                     # softmax activation"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286,"status":"ok","timestamp":1622274614948,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"wKfHUkHve46d","outputId":"c98ecd1e-9e7a-4a7e-ccb3-d136315519be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 26, 26, 32)        128       \n","_________________________________________________________________\n","activation (Activation)      (None, 26, 26, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 24, 24, 32)        0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 10, 10, 64)        256       \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 10, 10, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 2, 2, 128)         73856     \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 2, 2, 128)         512       \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 2, 2, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               262656    \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 512)               2048      \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                5130      \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 10)                0         \n","=================================================================\n","Total params: 409,962\n","Trainable params: 408,298\n","Non-trainable params: 1,664\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":294,"status":"ok","timestamp":1622274658357,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"J7lCg8Use9L6"},"outputs":[],"source":["# we'll use the same optimizer\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":371,"status":"ok","timestamp":1622274664945,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"NLZcYoKcgKt6"},"outputs":[],"source":["# data augmentation prevents overfitting by slightly changing the data randomly\n","# Keras has a great built-in feature to do automatic augmentation\n","\n","gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n","                         height_shift_range=0.08, zoom_range=0.08)\n","\n","test_gen = ImageDataGenerator()"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":290,"status":"ok","timestamp":1622274672962,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"_dcmuutGgPdl"},"outputs":[],"source":["# We can then feed our augmented data in batches\n","# Besides loss function considerations as before, this method actually results in significant memory savings\n","# because we are actually LOADING the data into the network in batches before processing each batch\n","\n","# Before the data was all loaded into memory, but then processed in batches.\n","\n","\n","test_generator = test_gen.flow(x=X_test, y=Y_test, batch_size=128)\n","train_generator = gen.flow(x=X_train, y=Y_train, batch_size=128)\n","#train_generator = gen.flow(X_train, Y_train, batch_size=128)\n","#test_generator = test_gen.flow(X_test, Y_test, batch_size=128)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":429161,"status":"ok","timestamp":1622275105642,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"czGzGlLfp_oO"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","468/468 [==============================] - 185s 391ms/step - loss: 0.3219 - accuracy: 0.8978 - val_loss: 0.0810 - val_accuracy: 0.9733\n","Epoch 2/20\n","468/468 [==============================] - 182s 390ms/step - loss: 0.0535 - accuracy: 0.9830 - val_loss: 0.0463 - val_accuracy: 0.9860\n","Epoch 3/20\n","468/468 [==============================] - 182s 389ms/step - loss: 0.0424 - accuracy: 0.9866 - val_loss: 0.0367 - val_accuracy: 0.9893\n","Epoch 4/20\n","468/468 [==============================] - 182s 389ms/step - loss: 0.0387 - accuracy: 0.9877 - val_loss: 0.0295 - val_accuracy: 0.9910\n","Epoch 5/20\n","468/468 [==============================] - 183s 391ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 0.0183 - val_accuracy: 0.9937\n","Epoch 6/20\n","468/468 [==============================] - 183s 391ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.0313 - val_accuracy: 0.9906\n","Epoch 7/20\n","468/468 [==============================] - 183s 390ms/step - loss: 0.0284 - accuracy: 0.9915 - val_loss: 0.0337 - val_accuracy: 0.9886\n","Epoch 8/20\n","468/468 [==============================] - 183s 391ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0415 - val_accuracy: 0.9869\n","Epoch 9/20\n","468/468 [==============================] - 181s 387ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.0251 - val_accuracy: 0.9925\n","Epoch 10/20\n","468/468 [==============================] - 179s 382ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0263 - val_accuracy: 0.9915\n","Epoch 11/20\n","468/468 [==============================] - 179s 382ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.0350 - val_accuracy: 0.9886\n","Epoch 12/20\n","468/468 [==============================] - 179s 382ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0203 - val_accuracy: 0.9929\n","Epoch 13/20\n","468/468 [==============================] - 178s 381ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0207 - val_accuracy: 0.9932\n","Epoch 14/20\n","468/468 [==============================] - 178s 381ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.0181 - val_accuracy: 0.9950\n","Epoch 15/20\n","468/468 [==============================] - 177s 379ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0328 - val_accuracy: 0.9881\n","Epoch 16/20\n","468/468 [==============================] - 178s 380ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0253 - val_accuracy: 0.9927\n","Epoch 17/20\n","468/468 [==============================] - 177s 379ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.0228 - val_accuracy: 0.9929\n","Epoch 18/20\n","468/468 [==============================] - 177s 378ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.0177 - val_accuracy: 0.9948\n","Epoch 19/20\n","468/468 [==============================] - 178s 379ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.0187 - val_accuracy: 0.9947\n","Epoch 20/20\n","468/468 [==============================] - 177s 379ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.0221 - val_accuracy: 0.9935\n"]},{"data":{"text/plain":["\u003ckeras.callbacks.History at 0x7f29f9328890\u003e"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["# We can now train our model which is fed data by our batch loader\n","# Steps per epoch should always be total size of the set divided by the batch size\n","\n","# SIGNIFICANT MEMORY SAVINGS (important for larger, deeper networks)\n","\n","model.fit_generator(train_generator, steps_per_epoch=60000//128, epochs=20, verbose=1, \n","                    validation_data=test_generator, validation_steps=10000//128)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3679,"status":"ok","timestamp":1622275136678,"user":{"displayName":"Rajesh kumar Ganesan","photoUrl":"","userId":"04176200856727597046"},"user_tz":-480},"id":"yxMXfFgTIf8d","outputId":"07cc4107-1f84-443b-a05a-e3807efe0b1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["313/313 [==============================] - 2s 4ms/step - loss: 0.0140 - accuracy: 0.9953\n","Test score: 0.014037882909178734\n","Test accuracy: 0.9952999949455261\n"]}],"source":["score = model.evaluate(X_test, Y_test)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPKY78tp/Jxzfj0oMsvJu2X","collapsed_sections":[],"name":"IU3_LAB1_Assignment.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}